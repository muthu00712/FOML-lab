import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# ----------------------------------------------------
# 1. Load Dataset
# ----------------------------------------------------

data = load_breast_cancer()
X = pd.DataFrame(data.data, columns=data.feature_names)
y = data.target

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# ----------------------------------------------------
# 2. Train Gradient Boosting Model
# ----------------------------------------------------
gb = GradientBoostingClassifier(
    n_estimators=200,
    learning_rate=0.1,
    max_depth=3,
    random_state=42
)

gb.fit(X_train, y_train)
y_pred = gb.predict(X_test)

# ----------------------------------------------------
# 3. Model Evaluation
# ----------------------------------------------------
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# ----------------------------------------------------
# 4. Confusion Matrix (Seaborn Heatmap)
# ----------------------------------------------------
plt.figure(figsize=(6,5))
sns.heatmap(confusion_matrix(y_test, y_pred),
            annot=True, cmap='Blues', fmt='d')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ----------------------------------------------------
# 5. Top 10 Important Features
# ----------------------------------------------------
feat_imp = pd.Series(gb.feature_importances_, index=X.columns)
top10 = feat_imp.sort_values(ascending=False).head(10)

plt.figure(figsize=(8,5))
sns.barplot(x=top10.values, y=top10.index, palette='viridis')
plt.title("Top 10 Important Features")
plt.xlabel("Importance")
plt.ylabel("Features")
plt.show()

# ----------------------------------------------------
# 6. Interpretation of Feature Importance
# ----------------------------------------------------
print("\nINTERPRETATION:")
print("""
The Gradient Boosting model highlights the most important features that help separate
benign from malignant tumors. Typically, features such as:

• mean radius  
• mean texture  
• mean perimeter  
• mean area  
• worst concavity  
• worst radius  

are clinically meaningful because malignant tumors tend to have:

- Irregular shapes (higher concavity and perimeter)
- Larger size (higher radius and area)
- More heterogeneous tissue texture

Thus, the model aligns strongly with real-world medical understanding:
malignant tumors look larger, denser, and more irregular on imaging.
""")
